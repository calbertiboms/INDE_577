# Single Neuron Linear Regression Model

This project implements a **Single Neuron Linear Regression Model**, demonstrating how a simple neuron with a linear activation function can be trained using gradient descent to predict continuous target values. In essence, this is a **linear regression** model where the neuron computes a weighted sum of input features to make predictions.

![Neuron Model](https://raw.githubusercontent.com/RandyRDavila/Data_Science_and_Machine_Learning_Spring_2022/refs/heads/main/Lecture_3/ThePerceptronImage.png)

### Key Concepts:
- **Single Neuron Linear Regression**: This project uses a neuron with a linear activation function, which means it performs a linear combination of the input features to predict a target value. This is equivalent to a standard linear regression model.
- **Learning Rate**: A key hyperparameter that controls the size of the updates during gradient descent. A well-tuned learning rate ensures faster convergence without overshooting the optimal solution.
- **Training & Prediction**: The neuron is trained on scaled input data, and predictions are generated by applying the trained weights to new, unseen data.

### Highlights:
- The model is trained using different learning rates to illustrate their effect on model performance.
- Visualizations are generated to compare the predicted outputs from the neuron model with the actual target values.
- Subplots show how changing the learning rate impacts the modelâ€™s ability to fit the data.

### Requirements:
- **Python 3.x**
- Libraries:
  - `numpy`: For numerical operations.
  - `matplotlib`: For visualizing the predictions.
  - `scikit-learn`: For scaling the input features.
